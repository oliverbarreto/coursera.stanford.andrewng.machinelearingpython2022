# Machine Learning
by Stanford University

Credits to [https://github.com/dibgerge/ml-coursera-python-assignments](https://github.com/dibgerge/ml-coursera-python-assignments) repo that provides a remastered version of all the assignments rewriten using a modern language and have been updated to use Jupyter Notebooks with Python. It also provides a valid easy-to-uese script to send all programming assignments to coursera's grading tool.

## About this Course
Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.

This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.

**Andrew Ng**
Taught by:Andrew Ng, Instructor
Founder, DeepLearning.AI & Co-founder, Coursera

**Language**	
English, Subtitles: Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, German, Russian, Hebrew, Spanish, Hindi, Japanese
How To Pass	Pass all graded assignments to complete the course.
User Ratings	
Average User Rating 4.9


# Diploma:
![Stanford Official Diploma](Diploma Oliver Stanford online Coursera - Machine Learning - F6K6NAH8PP97.png)

# Syllabus
## WEEK 1
## Introduction
Welcome to Machine Learning! In this module, we introduce the core idea of teaching a computer to learn concepts using data—without being explicitly programmed. The Course Wiki is under construction. Please visit the resources tab for the most complete and up-to-date information.

**week 1 material**
- 5 videos, 9 readings
- Video: Welcome to Machine Learning!
- Reading: Machine Learning Honor Code
- Video: Welcome
- Video: What is Machine Learning?
- Reading: What is Machine Learning?
- Reading: How to Use Discussion Forums
- Video: Supervised Learning
- Reading: Supervised Learning
- Video: Unsupervised Learning
- Reading: Unsupervised Learning
- Reading: Who are Mentors?
- Reading: Get to Know Your Classmates
- Reading: Frequently Asked Questions
- [Reading: Lecture Slides](/week1/Lecture01.pdf)
- Graded: Introduction

### Linear Regression with One Variable
Linear regression predicts a real-valued output based on an input value. We discuss the application of linear regression to housing price prediction, present the notion of a cost function, and introduce the gradient descent method for learning.

**week 1 material**
- 7 videos, 8 readings
- Video: Model Representation
- Reading: Model Representation
- Video: Cost Function
- Reading: Cost Function
- Video: Cost Function - Intuition I
- Reading: Cost Function - Intuition I
- Video: Cost Function - Intuition II
- Reading: Cost Function - Intuition II
- Video: Gradient Descent
- Reading: Gradient Descent
- Video: Gradient Descent Intuition
- Reading: Gradient Descent Intuition
- Video: Gradient Descent For Linear Regression
- Reading: Gradient Descent For Linear Regression
- [Reading: Lecture Slides](/week1/Lecture02.pdf)
- Graded: Linear Regression with One Variable

### Linear Algebra Review
This optional module provides a refresher on linear algebra concepts. Basic understanding of linear algebra is necessary for the rest of the course, especially as we begin to cover models with multiple variables.

**week 1 material**
- 6 videos, 7 readings, 1 practice quiz
- Video: Matrices and Vectors
- Reading: Matrices and Vectors
- Video: Addition and Scalar Multiplication
- Reading: Addition and Scalar Multiplication
- Video: Matrix Vector Multiplication
- Reading: Matrix Vector Multiplication
- Video: Matrix Matrix Multiplication
- Reading: Matrix Matrix Multiplication
- Video: Matrix Multiplication Properties
- Reading: Matrix Multiplication Properties
- Video: Inverse and Transpose
- Reading: Inverse and Transpose
- [Reading: Lecture Slides](/week1/Lecture03.pdf)
- Practice Quiz: Linear Algebra


## WEEK 2
### Linear Regression with Multiple Variables
What if your input has more than one value? In this module, we show how linear regression can be extended to accommodate multiple input features. We also discuss best practices for implementing linear regression.

**week 2 material**
- 8 videos, 16 readings
- Reading: Setting Up Your Programming Assignment Environment
- Reading: Access to MATLAB Online and the Exercise Files for MATLAB Users
- Reading: Installing Octave on Windows
- Reading: Installing Octave on Mac OS X (10.10 Yosemite and 10.9 Mavericks and Later)
- Reading: Installing Octave on Mac OS X (10.8 Mountain Lion and Earlier)
- Reading: Installing Octave on GNU/Linux
- Reading: More Octave/MATLAB resources
- Video: Multiple Features
- Reading: Multiple Features
- Video: Gradient Descent for Multiple Variables
- Reading: Gradient Descent For Multiple Variables
- Video: Gradient Descent in Practice I - Feature Scaling
- Reading: Gradient Descent in Practice I - Feature Scaling
- Video: Gradient Descent in Practice II - Learning Rate
- Reading: Gradient Descent in Practice II - Learning Rate
- Video: Features and Polynomial Regression
- Reading: Features and Polynomial Regression
- Video: Normal Equation
- Reading: Normal Equation
- Video: Normal Equation Noninvertibility
- Reading: Normal Equation Noninvertibility
- Video: Working on and Submitting Programming Assignments
- Reading: Programming tips from Mentors
- [Reading: Lecture Slides](week2/Lecture04.pdf)
- Graded: Linear Regression with Multiple Variables

### Octave/Matlab Tutorial
This course includes programming assignments designed to help you understand how to implement the learning algorithms in practice. To complete the programming assignments, you will need to use Octave or MATLAB. This module introduces Octave/Matlab and shows you how to submit an assignment.

**week 2 material**
- 6 videos, 2 readings
- Video: Basic Operations
- Video: Moving Data Around
- Video: Computing on Data
- Video: Plotting Data
- Video: Control Statements: for, while, if statement
- Video: Vectorization
- [Reading: Lecture Slides](/week2/Lecture05.pdf)
- Reading: Please read if you've switched from the original version

- Graded: Octave/Matlab Tutorial
- [Graded: Linear Regression](../code/assignments/ex1.pdf)

## WEEK 3
### Logistic Regression
Logistic regression is a method for classifying data into discrete outcomes. For example, we might use logistic regression to classify an email as spam or not spam. In this module, we introduce the notion of classification, the cost function for logistic regression, and the application of logistic regression to multi-class classification.


**week 3 material**
- 7 videos, 8 readings
- Video: Classification
- Reading: Classification
- Video: Hypothesis Representation
- Reading: Hypothesis Representation
- Video: Decision Boundary
- Reading: Decision Boundary
- Video: Cost Function
- Reading: Cost Function
- Video: Simplified Cost Function and Gradient Descent
- Reading: Simplified Cost Function and Gradient Descent
- Video: Advanced Optimization
- Reading: Advanced Optimization
- Video: Multiclass Classification: One-vs-all
- Reading: Multiclass Classification: One-vs-all
- [Reading: Lecture Slides](/week3/Lecture06.pdf)
- [Graded: Logistic Regression](../code/assignments/ex2.pdf)

### Regularization
Machine learning models need to generalize well to new examples that the model has not seen in practice. In this module, we introduce regularization, which helps prevent models from overfitting the training data.

**week 3 material**
- 4 videos, 5 readings
- Video: The Problem of Overfitting
- Reading: The Problem of Overfitting
- Video: Cost Function
- Reading: Cost Function
- Video: Regularized Linear Regression
- Reading: Regularized Linear Regression
- Video: Regularized Logistic Regression
- Reading: Regularized Logistic Regression
- [Reading: Lecture Slides](/week3/Lecture07.pdf)
- Graded: Regularization
- [Graded: Logistic Regression](../code/assignments/ex2.pdf)


## WEEK 4
### Neural Networks: Representation
Neural networks is a model inspired by how the brain works. It is widely used today in many applications: when your phone interprets and understand your voice commands, it is likely that a neural network is helping to understand your speech; when you cash a check, the machines that automatically read the digits also use neural networks.

**week 4 material**
- 7 videos, 6 readings
- Video: Non-linear Hypotheses
- Video: Neurons and the Brain
- Video: Model Representation I
- Reading: Model Representation I
- Video: Model Representation II
- Reading: Model Representation II
- Video: Examples and Intuitions I
- Reading: Examples and Intuitions I
- Video: Examples and Intuitions II
- Reading: Examples and Intuitions II
- Video: Multiclass Classification
- Reading: Multiclass Classification
- [Reading: Lecture Slides](/week4/Lecture08.pdf)
- [Graded: Neural Networks: Representation](../code/assignments/ex3.pdf)
- [Graded: Multi-class Classification and Neural Networks](../code/assignments/ex3.pdf)


## WEEK 5
### Neural Networks: Learning
In this module, we introduce the backpropagation algorithm that is used to help learn parameters for a neural network. At the end of this module, you will be implementing your own neural network for digit recognition.

**week 5 material**
- 8 videos, 8 readings
- Video: Cost Function
- Reading: Cost Function
- Video: Backpropagation Algorithm
- Reading: Backpropagation Algorithm
- Video: Backpropagation Intuition
- Reading: Backpropagation Intuition
- Video: Implementation Note: Unrolling Parameters
- Reading: Implementation Note: Unrolling Parameters
- Video: Gradient Checking
- Reading: Gradient Checking
- Video: Random Initialization
- Reading: Random Initialization
- Video: Putting It Together
- Reading: Putting It Together
- Video: Autonomous Driving
- [Reading: Lecture Slides](/week5/Lecture09.pdf)
- [Graded: Neural Networks: Learning](../code/assignments/ex4.pdf)


## WEEK 6
### Advice for Applying Machine Learning
Applying machine learning in practice is not always straightforward. In this module, we share best practices for applying machine learning in practice, and discuss the best ways to evaluate performance of the learned models.

**week 6 material**
- 7 videos, 7 readings
- Video: Deciding What to Try Next
- Video: Evaluating a Hypothesis
- Reading: Evaluating a Hypothesis
- Video: Model Selection and Train/Validation/Test Sets
- Reading: Model Selection and Train/Validation/Test Sets
- Video: Diagnosing Bias vs. Variance
- Reading: Diagnosing Bias vs. Variance
- Video: Regularization and Bias/Variance
- Reading: Regularization and Bias/Variance
- Video: Learning Curves
- Reading: Learning Curves
- Video: Deciding What to Do Next Revisited
- Reading: Deciding What to do Next Revisited
- [Reading: Lecture Slides](/week6/Lecture10.pdf)
- Graded: Advice for Applying Machine Learning
- [Graded: Regularized Linear Regression and Bias/Variance](../code/assignments/ex5.pdf)


### Machine Learning System Design
To optimize a machine learning algorithm, you’ll need to first understand where the biggest improvements can be made. In this module, we discuss how to understand the performance of a machine learning system with multiple parts, and also how to deal with skewed data.

**week 6 material**
- 5 videos, 3 readings
- Video: Prioritizing What to Work On
- Reading: Prioritizing What to Work On
- Video: Error Analysis
- Reading: Error Analysis
- Video: Error Metrics for Skewed Classes
- Video: Trading Off Precision and Recall
- Video: Data For Machine Learning
- [Reading: Lecture Slides](/week6/Lecture11.pdf)
- Graded: Machine Learning System Design


## WEEK 7
### Support Vector Machines
Support vector machines, or SVMs, is a machine learning algorithm for classification. We introduce the idea and intuitions behind SVMs and discuss how to use it in practice.

**week 7 material**
- 6 videos, 1 reading
- Video: Optimization Objective
- Video: Large Margin Intuition
- Video: Mathematics Behind Large Margin Classification
- Video: Kernels I
- Video: Kernels II
- Video: Using An SVM
- [Reading: Lecture Slides](/week7/Lecture12.pdf)
- [Graded: Support Vector Machines](../code/assignments/ex6.pdf)
- Graded: Support Vector Machines


## WEEK 8
### Unsupervised Learning
We use unsupervised learning to build models that help us understand our data better. We discuss the k-Means algorithm for clustering that enable us to learn groupings of unlabeled data points.

**week 8 material**
- 5 videos, 1 reading
- Video: Unsupervised Learning: Introduction
- Video: K-Means Algorithm
- Video: Optimization Objective
- Video: Random Initialization
- Video: Choosing the Number of Clusters
- [Reading: Lecture Slides](/week8/Lecture13.pdf)
- [Graded: Unsupervised Learning](../code/assignments/ex7.pdf)

### Dimensionality Reduction
In this module, we introduce Principal Components Analysis, and show how it can be used for data compression to speed up learning algorithms as well as for visualizations of complex datasets.

**week 8 material**
- 7 videos, 1 reading
- Video: Motivation I: Data Compression
- Video: Motivation II: Visualization
- Video: Principal Component Analysis Problem Formulation
- Video: Principal Component Analysis Algorithm
- Video: Reconstruction from Compressed Representation
- Video: Choosing the Number of Principal Components
- Video: Advice for Applying PCA
- [Reading: Lecture Slides](/week8/Lecture14.pdf)
- Graded: Principal Component Analysis
- Graded: K-Means Clustering and PCA


## WEEK 9
### Anomaly Detection
Given a large number of data points, we may sometimes want to figure out which ones vary significantly from the average. For example, in manufacturing, we may want to detect defects or anomalies. We show how a dataset can be modeled using a Gaussian distribution, and how the model can be used for anomaly detection.

**week 9 material**
- 8 videos, 1 reading
- Video: Problem Motivation
- Video: Gaussian Distribution
- Video: Algorithm
- Video: Developing and Evaluating an Anomaly Detection System
- Video: Anomaly Detection vs. Supervised Learning
- Video: Choosing What Features to Use
- Video: Multivariate Gaussian Distribution
- Video: Anomaly Detection using the Multivariate Gaussian Distribution
- [Reading: Lecture Slides](/week9/Lecture15.pdf)
- [Graded: Anomaly Detection](../code/assignments/ex8.pdf)

### Recommender Systems
When you buy a product online, most websites automatically recommend other products that you may like. Recommender systems look at patterns of activities between different users and different products to produce these recommendations. In this module, we introduce recommender algorithms such as the collaborative filtering algorithm and low-rank matrix factorization.


**week 9 material**
- 6 videos, 1 reading
- Video: Problem Formulation
- Video: Content Based Recommendations
- Video: Collaborative Filtering
- Video: Collaborative Filtering Algorithm
- Video: Vectorization: Low Rank Matrix Factorization
- Video: Implementational Detail: Mean Normalization
- [Reading: Lecture Slides](/week9/Lecture16.pdf)
- Graded: Recommender Systems
- Graded: Anomaly Detection and Recommender Systems


## WEEK 10
### Large Scale Machine Learning
Machine learning works best when there is an abundance of data to leverage for training. In this module, we discuss how to apply the machine learning algorithms with large datasets.

**week 10 material**
- 6 videos, 1 reading
- Video: Learning With Large Datasets
- Video: Stochastic Gradient Descent
- Video: Mini-Batch Gradient Descent
- Video: Stochastic Gradient Descent Convergence
- Video: Online Learning
- Video: Map Reduce and Data Parallelism
- [Reading: Lecture Slides](/week10/Lecture17.pdf)
- Graded: Large Scale Machine Learning


## WEEK 11
### Application Example: Photo OCR
Identifying and recognizing objects, words, and digits in an image is a challenging task. We discuss how a pipeline can be built to tackle this problem and how to analyze and improve the performance of such a system.

**week 11 material**
- 5 videos, 1 reading
- Video: Problem Description and Pipeline
- Video: Sliding Windows
- Video: Getting Lots of Data and Artificial Data
- Video: Ceiling Analysis: What Part of the Pipeline to Work on Next
- Video: Summary and Thank You
- [Reading: Lecture Slides](/week11/Lecture18.pdf)
- Graded: Application: Photo OCR


# How It Works
## General

### How do I pass the course?
  To earn your Course Certificate, you’ll need to earn a passing
    grade on each of the required assignments—these can be quizzes,
    peer-graded assignments, or programming assignments. Videos, readings,
    and practice exercises are there to help you prepare for the graded
    assignments. 

### What do start dates and end dates mean?
  Once you enroll,
    you’ll have access to all videos, readings, quizzes, and programming
    assignments (if applicable). If you choose to
    explore the course without purchasing, you may not be able to access
    certain assignments.  If you don’t finish all graded assignments before
    the end of the course, you can reset your deadlines. Your
    progress will be saved and you’ll be able to pick up where you left off.

### What are due dates? Is there a penalty for submitting my
      work after a due date?

  Within a course, there are suggested due dates to help you
    manage your schedule and keep coursework from piling up. Quizzes and
    programming assignments can be submitted late without consequence.
    However, it is possible that you won't receive a grade if you submit
    your peer-graded assignment too late because classmates usually review
    assignment within three days of the assignment deadline.

### Can I re-attempt an assignment?
      Yes. If you want to improve your grade, you can always try again.
        If you’re re-attempting a peer-graded assignment, re-submit your work
        as soon as you can to make sure there’s enough time for your classmates
        to review your work. In some cases you may need to wait before
        re-submitting a programming assignment or quiz. We encourage you to
        review course material during this delay.

### Programming assignments
        Programming assignments require you to write and run
        a computer program to solve a problem.

### What are programming assignments?
      Programming assignments include both assignment instructions and assignment parts.
      Instructions may include a link to a downloadable starter package that includes
      starter code, detailed guidelines, and other resources. Assignment parts are similar
      to individual quiz questions. Each part is a single coding task that can be
      completed one at a time.
    
### How are programming assignments graded?
      Programming assignments are graded automatically. If they use a built-in-algorithm
      you’ll see your grade within seconds. If they use a custom grader,
      you may need to wait up to an hour.

### Can I resubmit a programming assignment?
      You can resubmit all programming assignments to improve your grade.
      Follow the same steps as submitting a new assignment.

### What do I do if I have trouble submitting my assignment?
      If you have trouble submitting your assignment, we encourage you to
      visit your course Discussion Forums as many of your peers are likely to have
      had similar problems and have found a solution. Each programming assignment
      has its own sub-forum to discuss with peers.
    

